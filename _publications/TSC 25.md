---
title: "Memoir: Efficient KV Cache Optimization for LLM Inference in WebAssembly Runtimes"
collection: publications
# manuscripts代表journal，conference代表conference
category: conferences
# 下列这个代表你的目录

# 下列是简短的介绍
# excerpt: "We propose Memoir, a two-layer attention-driven KV cache optimization framework specifically designed for WebAssembly's linear memory layout, which achieves significant performance improvements (up to 416.1%) in LLM inference on edge devices and even outperforms native environments in some cases."

date: 2025-07-09
# 下列venue代表文章的状态，记得<i>和</i>是斜体
venue: 'Under review at <i>ACM International Conference on Architectural Support for Programming Languages and Operating Systems(ASPLOS)</i>'
paperurl: 'https://drive.google.com/file/d/1nk6Jl0UZLD7CczVP3a2z7R7sU1VWlsfS/view?usp=sharing'
citation: '<u>Zirui Wang</u>, Yudan Long, Yuxin Su†, Dan Li, and Zibin Zheng'
---
