---
title: "Memoir: Efficient KV Cache Optimization for LLM Inference in WebAssembly Runtimes"
collection: publications
# manuscripts代表Journal，conferences代表Conference
category: conferences
# 下列这个代表你的目录

# 下列是简短的介绍
# excerpt: "We propose Memoir, a two-layer attention-driven KV cache optimization framework specifically designed for WebAssembly's linear memory layout, which achieves significant performance improvements (up to 416.1%) in LLM inference on edge devices and even outperforms native environments in some cases."

date: 2026-01-15
# 下列venue代表文章的状态，记得<i>和</i>是斜体
venue: 'Under review at <i>The IEEE International Conference on Distributed Computing Systems (ICDCS) 2026</i>'
paperurl: 'https://drive.google.com/file/d/1nk6Jl0UZLD7CczVP3a2z7R7sU1VWlsfS/view?usp=sharing'
citation: '<u>Zirui Wang</u>, Yudan Long, Yuxin Su†, Dan Li and Zibin Zheng'
---
